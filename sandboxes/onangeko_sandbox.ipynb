{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6abf325a4bde6fb9",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-05T11:57:40.747864Z",
     "start_time": "2024-04-05T11:57:40.744801Z"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import torch\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Info  FPS: 12 Width: 640 Height: 480\n"
     ]
    }
   ],
   "source": [
    "path_to_weights = '../sandboxes/best.pt'\n",
    "model = YOLO(path_to_weights)\n",
    "device = 'mps:0' if torch.backends.mps.is_available() else 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "video ='https://hd-auth.skylinewebcams.com/live.m3u8?a=67sg4qmmrche0a4hrkmkr8g6j2'\n",
    "\n",
    "HEIGHT = 640\n",
    "WIDTH = 480\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)\n",
    "\n",
    "print('Video Info' + '  FPS: '+str(int(fps))+' Width: '+str(HEIGHT)+' Height: '+str(WIDTH))\n",
    "\n",
    "\n",
    "\n",
    "# Store the track history\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "        results = model.track(frame, persist=True,classes=[0],conf=0.5,device=device,verbose=False)\n",
    "        for result in results:\n",
    "            if result.boxes is None or result.boxes.id is None:\n",
    "                continue\n",
    "            # Get the boxes and track IDs\n",
    "            else:\n",
    "                boxes = result.boxes.xywh.cpu()\n",
    "                track_ids = result.boxes.id.cpu().numpy().astype(int)\n",
    "                # Plot the tracks and draw bounding boxes without class annotations\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    x, y, w, h = box\n",
    "                    # Calculate top left corner of the bounding box\n",
    "                    top_left = int(x - w / 2), int(y - h / 2)\n",
    "                    bottom_right = int(x + w / 2), int(y + h / 2)\n",
    "                    \n",
    "                    # Draw bounding box\n",
    "                    cv2.rectangle(frame, top_left, bottom_right, (0, 0, 255), 2)\n",
    "                    \n",
    "                    track = track_history[track_id]\n",
    "                    track.append((int(x), int(y)))  # x, y center point\n",
    "                    if len(track) > 30:\n",
    "                        track.pop(0)\n",
    "                    \n",
    "                    # Draw the tracking lines\n",
    "                    if len(track) > 1:\n",
    "                        for i in range(1, len(track)):\n",
    "                            cv2.line(frame, track[i - 1], track[i], (0, 255, 0), 2)\n",
    "                # Display the annotated frame\n",
    "                cv2.imshow(\"YOLOv8 Tracking\", frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T11:57:46.756302Z",
     "start_time": "2024-04-05T11:57:40.749940Z"
    }
   },
   "id": "999d02b0e3bed1c9",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Info - FPS: 12 Width: 640 Height: 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/_q2t9dnn149gm7fk6whh5f080000gn/T/ipykernel_39130/2387429360.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = model.names[int(cls)]\n"
     ]
    }
   ],
   "source": [
    "# Assuming the YOLO and model initialization code is defined elsewhere\n",
    "\n",
    "path_to_weights = '../sandboxes/crosswalk_detect.pt'\n",
    "model = YOLO(path_to_weights)\n",
    "device = 'mps:0' if torch.backends.mps.is_available() else 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "video ='https://hd-auth.skylinewebcams.com/live.m3u8?a=67sg4qmmrche0a4hrkmkr8g6j2'\n",
    "\n",
    "HEIGHT = 640\n",
    "WIDTH = 480\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)\n",
    "\n",
    "print(f'Video Info - FPS: {int(fps)} Width: {HEIGHT} Height: {WIDTH}')\n",
    "\n",
    "# Flag to check if inference was already done\n",
    "inference_done = False\n",
    "results = None  # To store the inference results\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        if not inference_done:\n",
    "            # Run YOLOv8 inference on the first frame\n",
    "            results = model(frame, conf=0.2, device=device, verbose=False)\n",
    "            inference_done = True\n",
    "        # Visualize the results on every frame\n",
    "        if results is not None:\n",
    "            for result in results[0].boxes:  # Loop through detections\n",
    "                # Extract bounding box coordinates\n",
    "                xmin, ymin, xmax, ymax = result.xyxy.cpu().numpy()[0].astype(int)\n",
    "                conf = result.conf.cpu().numpy().astype(float)\n",
    "                cls = result.cls.cpu().numpy().astype(int)\n",
    "                label = model.names[int(cls)]  \n",
    "\n",
    "                # Draw bounding box and label on the frame\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label, (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "\n",
    "        # Display the frame with detections\n",
    "        cv2.imshow(\"YOLOv8 Inference\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T11:57:55.810346Z",
     "start_time": "2024-04-05T11:57:53.513926Z"
    }
   },
   "id": "c1611b5b1f664e24",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ed5b284ff06fa977"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
